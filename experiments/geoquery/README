== Introduction == 
Basic setup for running semantic parsing experiments on the GeoQuery
data set. The original data set is available from 

http://www.cs.utexas.edu/users/ml/nldata/geoquery.html

This setup uses a reformatted version of this data from the University
of Washington Semantic Parsing Framework, available here:

https://bitbucket.org/yoavartzi/spf

== Directory structure == 
data - reformatted version of the GeoQuery data into a jklol-readable
format. This data is automatically generated by reformat_data.sh

grammar - contains the lexicon and rules for the semantic parser. The
lexicon is automatically generated by generate_lexicon.py.

scripts - scripts for lexicon generation, training and testing a
semantic parser.


== Running the Experiment ==
The run_experiments.sh script will generate a lexicon, train a
semantic parser, and evaluate its training error. It should be run
from the root jklol directory, as follows:

./experiments/geoquery/scripts/run_experiment.sh

This script trains and evaluates a CCG semantic parser on the entire
GeoQuery data set using a (very naively) automatically generated
lexicon. The parser is trained as a linear model using the structured
perceptron algorithm.

Running the experiment will also save a semantic parsing model to
"out.ser" in the base directory. This model can be used to parse new
text using the parse.sh script. For example:

./experiments/geoquery/scripts/parse.sh city in Texas

